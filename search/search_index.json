{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"StackOne AI SDK # StackOne AI SDK provides an AI-friendly interface for accessing various SaaS tools through the StackOne Unified API. This SDK is available on PyPI for python projects. There is a node version in the works. Installation # # Using uv uv add stackone-ai # Using pip pip install stackone-ai How to use these docs # All examples are complete and runnable. We use uv for easy python dependency management. Install uv: curl -LsSf https://astral.sh/uv/install.sh | sh To run this example, clone the repo, install the dependencies (one-time setup) and run the script: git clone https://github.com/stackoneHQ/stackone-ai-python.git cd stackone-ai-python # Install dependencies uv sync --all-extras # Run the example uv run examples/index.py Authentication # Set the STACKONE_API_KEY environment variable: export STACKONE_API_KEY = <your-api-key> or load from a .env file: from dotenv import load_dotenv load_dotenv () Account IDs # StackOne uses account IDs to identify different integrations. See the example stackone-account-ids.md for more details. This example will hardcode the account ID: account_id = \"45072196112816593343\" Quickstart # from stackone_ai import StackOneToolSet def quickstart (): toolset = StackOneToolSet () # Get all HRIS-related tools tools = toolset . get_tools ( \"hris_*\" , account_id = account_id ) # Use a specific tool employee_tool = tools . get_tool ( \"hris_list_employees\" ) assert employee_tool is not None employees = employee_tool . execute () assert employees is not None if __name__ == \"__main__\" : quickstart () Next Steps # Check out some more documentation: StackOne Account IDs Error Handling Available Tools File Uploads Or get started with an integration: OpenAI LangChain CrewAI LangGraph","title":"Home"},{"location":"#stackone-ai-sdk","text":"StackOne AI SDK provides an AI-friendly interface for accessing various SaaS tools through the StackOne Unified API. This SDK is available on PyPI for python projects. There is a node version in the works.","title":"StackOne AI SDK"},{"location":"#installation","text":"# Using uv uv add stackone-ai # Using pip pip install stackone-ai","title":"Installation"},{"location":"#how-to-use-these-docs","text":"All examples are complete and runnable. We use uv for easy python dependency management. Install uv: curl -LsSf https://astral.sh/uv/install.sh | sh To run this example, clone the repo, install the dependencies (one-time setup) and run the script: git clone https://github.com/stackoneHQ/stackone-ai-python.git cd stackone-ai-python # Install dependencies uv sync --all-extras # Run the example uv run examples/index.py","title":"How to use these docs"},{"location":"#authentication","text":"Set the STACKONE_API_KEY environment variable: export STACKONE_API_KEY = <your-api-key> or load from a .env file: from dotenv import load_dotenv load_dotenv ()","title":"Authentication"},{"location":"#account-ids","text":"StackOne uses account IDs to identify different integrations. See the example stackone-account-ids.md for more details. This example will hardcode the account ID: account_id = \"45072196112816593343\"","title":"Account IDs"},{"location":"#quickstart","text":"from stackone_ai import StackOneToolSet def quickstart (): toolset = StackOneToolSet () # Get all HRIS-related tools tools = toolset . get_tools ( \"hris_*\" , account_id = account_id ) # Use a specific tool employee_tool = tools . get_tool ( \"hris_list_employees\" ) assert employee_tool is not None employees = employee_tool . execute () assert employees is not None if __name__ == \"__main__\" : quickstart ()","title":"Quickstart"},{"location":"#next-steps","text":"Check out some more documentation: StackOne Account IDs Error Handling Available Tools File Uploads Or get started with an integration: OpenAI LangChain CrewAI LangGraph","title":"Next Steps"},{"location":"available-tools/","text":"Available Tools # Get available tools from your StackOne organisation based on the account id. This example demonstrates different ways to filter and organize tools: Getting all available tools Filtering by vertical Using multiple patterns for cross-vertical functionality Filtering by specific operations Combining multiple operation patterns TODO: get_account_tools(account_id=\"your_account_id\") uv run examples/available_tools.py from dotenv import load_dotenv from stackone_ai import StackOneToolSet load_dotenv () def get_available_tools () -> None : toolset = StackOneToolSet () We can get all tools using the get_tools method. all_tools = toolset . get_tools () assert len ( all_tools ) > 100 , \"Expected at least 100 tools in total\" Then, let's get just HRIS tools using a filter. This filter accepts glob patterns. hris_tools = toolset . get_tools ( \"hris_*\" ) assert len ( hris_tools ) > 10 , \"Expected at least 10 HRIS tools\" Filter with multiple patterns. This will return all tools that match either pattern (OR operator). people_tools = toolset . get_tools ( [ \"hris_*employee*\" , \"crm_*contact*\" , ] ) assert len ( people_tools ) > 20 , \"Expected at least 20 people-related tools\" for tool in people_tools : assert \"employee\" in tool . name or \"contact\" in tool . name , ( f \"Tool { tool . name } doesn't contain 'employee' or 'contact'\" ) Filter by specific operations across all verticals using a glob pattern. upload_tools = toolset . get_tools ( \"*upload*\" ) assert len ( upload_tools ) > 0 , \"Expected at least one upload tool\" for tool in upload_tools : assert \"upload\" in tool . name . lower (), f \"Tool { tool . name } doesn't contain 'upload'\" The exclude pattern is also supported. non_hris_tools = toolset . get_tools ( \"!hris_*\" ) assert len ( non_hris_tools ) > 0 , \"Expected at least one non-HRIS tool\" for tool in non_hris_tools : assert not tool . name . startswith ( \"hris_\" ), f \"Tool { tool . name } should not be an HRIS tool\" More hectic example: list_tools = toolset . get_tools ( [ \"*list*\" , # Include list operations \"*search*\" , # Include search operations \"!*delete*\" , # Exclude delete operations \"!*remove*\" , # Exclude remove operations ] ) assert len ( list_tools ) > 0 , \"Expected at least one list/search tool\" for tool in list_tools : # Should match positive patterns assert any ( op in tool . name . lower () for op in [ \"list\" , \"search\" ]), ( f \"Tool { tool . name } doesn't contain 'list' or 'search'\" ) # Should not match negative patterns assert not any ( op in tool . name . lower () for op in [ \"delete\" , \"remove\" ]), ( f \"Tool { tool . name } contains excluded operation\" ) if __name__ == \"__main__\" : get_available_tools ()","title":"Available Tools"},{"location":"available-tools/#available-tools","text":"Get available tools from your StackOne organisation based on the account id. This example demonstrates different ways to filter and organize tools: Getting all available tools Filtering by vertical Using multiple patterns for cross-vertical functionality Filtering by specific operations Combining multiple operation patterns TODO: get_account_tools(account_id=\"your_account_id\") uv run examples/available_tools.py from dotenv import load_dotenv from stackone_ai import StackOneToolSet load_dotenv () def get_available_tools () -> None : toolset = StackOneToolSet () We can get all tools using the get_tools method. all_tools = toolset . get_tools () assert len ( all_tools ) > 100 , \"Expected at least 100 tools in total\" Then, let's get just HRIS tools using a filter. This filter accepts glob patterns. hris_tools = toolset . get_tools ( \"hris_*\" ) assert len ( hris_tools ) > 10 , \"Expected at least 10 HRIS tools\" Filter with multiple patterns. This will return all tools that match either pattern (OR operator). people_tools = toolset . get_tools ( [ \"hris_*employee*\" , \"crm_*contact*\" , ] ) assert len ( people_tools ) > 20 , \"Expected at least 20 people-related tools\" for tool in people_tools : assert \"employee\" in tool . name or \"contact\" in tool . name , ( f \"Tool { tool . name } doesn't contain 'employee' or 'contact'\" ) Filter by specific operations across all verticals using a glob pattern. upload_tools = toolset . get_tools ( \"*upload*\" ) assert len ( upload_tools ) > 0 , \"Expected at least one upload tool\" for tool in upload_tools : assert \"upload\" in tool . name . lower (), f \"Tool { tool . name } doesn't contain 'upload'\" The exclude pattern is also supported. non_hris_tools = toolset . get_tools ( \"!hris_*\" ) assert len ( non_hris_tools ) > 0 , \"Expected at least one non-HRIS tool\" for tool in non_hris_tools : assert not tool . name . startswith ( \"hris_\" ), f \"Tool { tool . name } should not be an HRIS tool\" More hectic example: list_tools = toolset . get_tools ( [ \"*list*\" , # Include list operations \"*search*\" , # Include search operations \"!*delete*\" , # Exclude delete operations \"!*remove*\" , # Exclude remove operations ] ) assert len ( list_tools ) > 0 , \"Expected at least one list/search tool\" for tool in list_tools : # Should match positive patterns assert any ( op in tool . name . lower () for op in [ \"list\" , \"search\" ]), ( f \"Tool { tool . name } doesn't contain 'list' or 'search'\" ) # Should not match negative patterns assert not any ( op in tool . name . lower () for op in [ \"delete\" , \"remove\" ]), ( f \"Tool { tool . name } contains excluded operation\" ) if __name__ == \"__main__\" : get_available_tools ()","title":"Available Tools"},{"location":"crewai-integration/","text":"Crewai Integration # This example demonstrates how to use StackOne tools with CrewAI. CrewAI uses LangChain tools natively. uv run examples/crewai_integration.py from crewai import Agent , Crew , Task from stackone_ai import StackOneToolSet account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" def crewai_integration (): toolset = StackOneToolSet () tools = toolset . get_tools ( \"hris_*\" , account_id = account_id ) # CrewAI uses LangChain tools natively langchain_tools = tools . to_langchain () assert len ( langchain_tools ) > 0 , \"Expected at least one LangChain tool\" for tool in langchain_tools : assert hasattr ( tool , \"name\" ), \"Expected tool to have name\" assert hasattr ( tool , \"description\" ), \"Expected tool to have description\" assert hasattr ( tool , \"_run\" ), \"Expected tool to have _run method\" agent = Agent ( role = \"HR Manager\" , goal = f \"What is the employee with the id { employee_id } ?\" , backstory = \"With over 10 years of experience in HR and employee management, \" \"you excel at finding patterns in complex datasets.\" , llm = \"gpt-4o-mini\" , tools = langchain_tools , max_iter = 2 , ) task = Task ( description = \"What is the employee with the id c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA?\" , agent = agent , expected_output = \"A JSON object containing the employee's information\" , ) crew = Crew ( agents = [ agent ], tasks = [ task ]) result = crew . kickoff () assert result is not None , \"Expected result to be returned\" if __name__ == \"__main__\" : crewai_integration ()","title":"CrewAI"},{"location":"crewai-integration/#crewai-integration","text":"This example demonstrates how to use StackOne tools with CrewAI. CrewAI uses LangChain tools natively. uv run examples/crewai_integration.py from crewai import Agent , Crew , Task from stackone_ai import StackOneToolSet account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" def crewai_integration (): toolset = StackOneToolSet () tools = toolset . get_tools ( \"hris_*\" , account_id = account_id ) # CrewAI uses LangChain tools natively langchain_tools = tools . to_langchain () assert len ( langchain_tools ) > 0 , \"Expected at least one LangChain tool\" for tool in langchain_tools : assert hasattr ( tool , \"name\" ), \"Expected tool to have name\" assert hasattr ( tool , \"description\" ), \"Expected tool to have description\" assert hasattr ( tool , \"_run\" ), \"Expected tool to have _run method\" agent = Agent ( role = \"HR Manager\" , goal = f \"What is the employee with the id { employee_id } ?\" , backstory = \"With over 10 years of experience in HR and employee management, \" \"you excel at finding patterns in complex datasets.\" , llm = \"gpt-4o-mini\" , tools = langchain_tools , max_iter = 2 , ) task = Task ( description = \"What is the employee with the id c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA?\" , agent = agent , expected_output = \"A JSON object containing the employee's information\" , ) crew = Crew ( agents = [ agent ], tasks = [ task ]) result = crew . kickoff () assert result is not None , \"Expected result to be returned\" if __name__ == \"__main__\" : crewai_integration ()","title":"Crewai Integration"},{"location":"custom-base-url/","text":"Custom Base Url # Example demonstrating how to use a custom base URL with StackOne tools. This is useful for: 1. Testing against development APIs 2. Working with self-hosted StackOne instances Usage: uv run examples/custom_base_url.py from stackone_ai.toolset import StackOneToolSet def custom_base_url (): Default base URL default_toolset = StackOneToolSet () hris_tools = default_toolset . get_tools ( filter_pattern = \"hris_*\" ) assert len ( hris_tools ) > 0 assert hris_tools [ 0 ] . _execute_config . url . startswith ( \"https://api.stackone.com\" ) Custom base URL dev_toolset = StackOneToolSet ( base_url = \"https://api.example-dev.com\" ) dev_hris_tools = dev_toolset . get_tools ( filter_pattern = \"hris_*\" ) Note this uses the same tools but substitutes the base URL assert len ( dev_hris_tools ) > 0 assert dev_hris_tools [ 0 ] . _execute_config . url . startswith ( \"https://api.example-dev.com\" ) if __name__ == \"__main__\" : custom_base_url ()","title":"Custom Base Url"},{"location":"custom-base-url/#custom-base-url","text":"Example demonstrating how to use a custom base URL with StackOne tools. This is useful for: 1. Testing against development APIs 2. Working with self-hosted StackOne instances Usage: uv run examples/custom_base_url.py from stackone_ai.toolset import StackOneToolSet def custom_base_url (): Default base URL default_toolset = StackOneToolSet () hris_tools = default_toolset . get_tools ( filter_pattern = \"hris_*\" ) assert len ( hris_tools ) > 0 assert hris_tools [ 0 ] . _execute_config . url . startswith ( \"https://api.stackone.com\" ) Custom base URL dev_toolset = StackOneToolSet ( base_url = \"https://api.example-dev.com\" ) dev_hris_tools = dev_toolset . get_tools ( filter_pattern = \"hris_*\" ) Note this uses the same tools but substitutes the base URL assert len ( dev_hris_tools ) > 0 assert dev_hris_tools [ 0 ] . _execute_config . url . startswith ( \"https://api.example-dev.com\" ) if __name__ == \"__main__\" : custom_base_url ()","title":"Custom Base Url"},{"location":"error-handling/","text":"Error Handling # This example demonstrates error handling when using the StackOne SDK. Run the following command to see the output: uv run examples/error_handling.py import os from dotenv import load_dotenv from stackone_ai import StackOneToolSet from stackone_ai.models import StackOneAPIError from stackone_ai.toolset import ToolsetConfigError , ToolsetLoadError load_dotenv () def error_handling () -> None : Example 1: Configuration error - missing API key original_api_key = os . environ . pop ( \"STACKONE_API_KEY\" , None ) try : try : StackOneToolSet ( api_key = None ) raise AssertionError ( \"Expected ToolsetConfigError\" ) except ToolsetConfigError as e : assert ( str ( e ) == \"API key must be provided either through api_key parameter or STACKONE_API_KEY environment variable\" ) finally : if original_api_key : os . environ [ \"STACKONE_API_KEY\" ] = original_api_key Example 2: Invalid vertical error toolset = StackOneToolSet () try : # Use a non-existent vertical to trigger error tools = toolset . get_tools ( \"nonexistent_vertical_*\" ) # If we get here, no tools were found but no error was raised assert len ( tools ) == 0 , \"Expected no tools for nonexistent vertical\" except ToolsetLoadError as e : assert \"Error loading tools\" in str ( e ) Example 3: API error - invalid request toolset = StackOneToolSet () tools = toolset . get_tools ( \"crm_*\" ) # Try to make an API call without required parameters list_contacts = tools . get_tool ( \"crm_list_contacts\" ) assert list_contacts is not None , \"Expected crm_list_contacts tool to exist\" try : # Execute without required parameters should raise error list_contacts . execute ({}) raise AssertionError ( \"Expected StackOneAPIError\" ) except StackOneAPIError as e : assert e . status_code >= 400 , \"Expected error status code\" assert e . response_body is not None , \"Expected error response body\" if __name__ == \"__main__\" : error_handling ()","title":"Error Handling"},{"location":"error-handling/#error-handling","text":"This example demonstrates error handling when using the StackOne SDK. Run the following command to see the output: uv run examples/error_handling.py import os from dotenv import load_dotenv from stackone_ai import StackOneToolSet from stackone_ai.models import StackOneAPIError from stackone_ai.toolset import ToolsetConfigError , ToolsetLoadError load_dotenv () def error_handling () -> None : Example 1: Configuration error - missing API key original_api_key = os . environ . pop ( \"STACKONE_API_KEY\" , None ) try : try : StackOneToolSet ( api_key = None ) raise AssertionError ( \"Expected ToolsetConfigError\" ) except ToolsetConfigError as e : assert ( str ( e ) == \"API key must be provided either through api_key parameter or STACKONE_API_KEY environment variable\" ) finally : if original_api_key : os . environ [ \"STACKONE_API_KEY\" ] = original_api_key Example 2: Invalid vertical error toolset = StackOneToolSet () try : # Use a non-existent vertical to trigger error tools = toolset . get_tools ( \"nonexistent_vertical_*\" ) # If we get here, no tools were found but no error was raised assert len ( tools ) == 0 , \"Expected no tools for nonexistent vertical\" except ToolsetLoadError as e : assert \"Error loading tools\" in str ( e ) Example 3: API error - invalid request toolset = StackOneToolSet () tools = toolset . get_tools ( \"crm_*\" ) # Try to make an API call without required parameters list_contacts = tools . get_tool ( \"crm_list_contacts\" ) assert list_contacts is not None , \"Expected crm_list_contacts tool to exist\" try : # Execute without required parameters should raise error list_contacts . execute ({}) raise AssertionError ( \"Expected StackOneAPIError\" ) except StackOneAPIError as e : assert e . status_code >= 400 , \"Expected error status code\" assert e . response_body is not None , \"Expected error response body\" if __name__ == \"__main__\" : error_handling ()","title":"Error Handling"},{"location":"file-uploads/","text":"File Uploads # Example demonstrating file upload functionality using StackOne. Shows how to upload an employee document using an HRIS integration. This example is runnable with the following command: uv run examples/file_upload_example.py import base64 import tempfile from pathlib import Path from dotenv import load_dotenv from stackone_ai import StackOneToolSet load_dotenv () account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" Resume content # This is a sample resume content that will be uploaded using the hris_upload_employee_document tool. resume_content = \"\"\" JOHN DOE Software Engineer EXPERIENCE Senior Developer - Tech Corp 2020-Present - Led development of core features - Managed team of 5 engineers EDUCATION BS Computer Science University of Technology 2016-2020 \"\"\" Upload employee document # This function uploads a resume using the hris_upload_employee_document tool. def upload_employee_document () -> None : with tempfile . TemporaryDirectory () as temp_dir : resume_file = Path ( temp_dir ) / \"resume.pdf\" resume_file . write_text ( resume_content ) toolset = StackOneToolSet () tools = toolset . get_tools ( \"hris_*\" , account_id = account_id ) upload_tool = tools . get_tool ( \"hris_upload_employee_document\" ) assert upload_tool is not None with open ( resume_file , \"rb\" ) as f : file_content = base64 . b64encode ( f . read ()) . decode () upload_params = { \"x-account-id\" : account_id , \"id\" : employee_id , \"name\" : \"resume\" , \"content\" : file_content , \"category\" : { \"value\" : \"shared\" }, \"file_format\" : { \"value\" : \"txt\" }, } result = upload_tool . execute ( upload_params ) assert result is not None assert result . get ( \"message\" ) == \"File uploaded successfully\" if __name__ == \"__main__\" : upload_employee_document ()","title":"File Uploads"},{"location":"file-uploads/#file-uploads","text":"Example demonstrating file upload functionality using StackOne. Shows how to upload an employee document using an HRIS integration. This example is runnable with the following command: uv run examples/file_upload_example.py import base64 import tempfile from pathlib import Path from dotenv import load_dotenv from stackone_ai import StackOneToolSet load_dotenv () account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\"","title":"File Uploads"},{"location":"file-uploads/#resume-content","text":"This is a sample resume content that will be uploaded using the hris_upload_employee_document tool. resume_content = \"\"\" JOHN DOE Software Engineer EXPERIENCE Senior Developer - Tech Corp 2020-Present - Led development of core features - Managed team of 5 engineers EDUCATION BS Computer Science University of Technology 2016-2020 \"\"\"","title":"Resume content"},{"location":"file-uploads/#upload-employee-document","text":"This function uploads a resume using the hris_upload_employee_document tool. def upload_employee_document () -> None : with tempfile . TemporaryDirectory () as temp_dir : resume_file = Path ( temp_dir ) / \"resume.pdf\" resume_file . write_text ( resume_content ) toolset = StackOneToolSet () tools = toolset . get_tools ( \"hris_*\" , account_id = account_id ) upload_tool = tools . get_tool ( \"hris_upload_employee_document\" ) assert upload_tool is not None with open ( resume_file , \"rb\" ) as f : file_content = base64 . b64encode ( f . read ()) . decode () upload_params = { \"x-account-id\" : account_id , \"id\" : employee_id , \"name\" : \"resume\" , \"content\" : file_content , \"category\" : { \"value\" : \"shared\" }, \"file_format\" : { \"value\" : \"txt\" }, } result = upload_tool . execute ( upload_params ) assert result is not None assert result . get ( \"message\" ) == \"File uploaded successfully\" if __name__ == \"__main__\" : upload_employee_document ()","title":"Upload employee document"},{"location":"langchain-integration/","text":"Langchain Integration # This example demonstrates how to use StackOne tools with LangChain. uv run examples/langchain_integration.py from dotenv import load_dotenv from langchain_openai import ChatOpenAI from stackone_ai import StackOneToolSet load_dotenv () account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" def langchain_integration () -> None : toolset = StackOneToolSet () tools = toolset . get_tools ( \"hris_*\" , account_id = account_id ) # Convert to LangChain format and verify langchain_tools = tools . to_langchain () assert len ( langchain_tools ) > 0 , \"Expected at least one LangChain tool\" # Verify tool structure for tool in langchain_tools : assert hasattr ( tool , \"name\" ), \"Expected tool to have name\" assert hasattr ( tool , \"description\" ), \"Expected tool to have description\" assert hasattr ( tool , \"_run\" ), \"Expected tool to have _run method\" assert hasattr ( tool , \"args_schema\" ), \"Expected tool to have args_schema\" # Create model with tools model = ChatOpenAI ( model = \"gpt-4o-mini\" ) model_with_tools = model . bind_tools ( langchain_tools ) result = model_with_tools . invoke ( f \"Can you get me information about employee with ID: { employee_id } ?\" ) assert result . tool_calls is not None for tool_call in result . tool_calls : tool = tools . get_tool ( tool_call [ \"name\" ]) if tool : result = tool . execute ( tool_call [ \"args\" ]) assert result is not None assert result . get ( \"data\" ) is not None if __name__ == \"__main__\" : langchain_integration ()","title":"LangChain"},{"location":"langchain-integration/#langchain-integration","text":"This example demonstrates how to use StackOne tools with LangChain. uv run examples/langchain_integration.py from dotenv import load_dotenv from langchain_openai import ChatOpenAI from stackone_ai import StackOneToolSet load_dotenv () account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" def langchain_integration () -> None : toolset = StackOneToolSet () tools = toolset . get_tools ( \"hris_*\" , account_id = account_id ) # Convert to LangChain format and verify langchain_tools = tools . to_langchain () assert len ( langchain_tools ) > 0 , \"Expected at least one LangChain tool\" # Verify tool structure for tool in langchain_tools : assert hasattr ( tool , \"name\" ), \"Expected tool to have name\" assert hasattr ( tool , \"description\" ), \"Expected tool to have description\" assert hasattr ( tool , \"_run\" ), \"Expected tool to have _run method\" assert hasattr ( tool , \"args_schema\" ), \"Expected tool to have args_schema\" # Create model with tools model = ChatOpenAI ( model = \"gpt-4o-mini\" ) model_with_tools = model . bind_tools ( langchain_tools ) result = model_with_tools . invoke ( f \"Can you get me information about employee with ID: { employee_id } ?\" ) assert result . tool_calls is not None for tool_call in result . tool_calls : tool = tools . get_tool ( tool_call [ \"name\" ]) if tool : result = tool . execute ( tool_call [ \"args\" ]) assert result is not None assert result . get ( \"data\" ) is not None if __name__ == \"__main__\" : langchain_integration ()","title":"Langchain Integration"},{"location":"langgraph-tool-node/","text":"Langgraph Tool Node # TODO!! This example demonstrates how to use StackOne tools with LangGraph. uv run examples/langgraph_tool_node.py from dotenv import load_dotenv from stackone_ai import StackOneToolSet load_dotenv () account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" def langgraph_tool_node () -> None : Demonstrate basic LangGraph integration with StackOne tools. toolset = StackOneToolSet () tools = toolset . get_tools ( \"hris_*\" , account_id = account_id ) # Verify we have the tools we need assert len ( tools ) > 0 , \"Expected at least one HRIS tool\" employee_tool = tools . get_tool ( \"hris_get_employee\" ) assert employee_tool is not None , \"Expected hris_get_employee tool\" # TODO: Add LangGraph specific integration # For now, just verify the tools are properly configured langchain_tools = tools . to_langchain () assert len ( langchain_tools ) > 0 , \"Expected LangChain tools\" assert all ( hasattr ( tool , \"_run\" ) for tool in langchain_tools ), \"Expected all tools to have _run method\" if __name__ == \"__main__\" : langgraph_tool_node ()","title":"Langgraph Tool Node"},{"location":"langgraph-tool-node/#langgraph-tool-node","text":"TODO!! This example demonstrates how to use StackOne tools with LangGraph. uv run examples/langgraph_tool_node.py from dotenv import load_dotenv from stackone_ai import StackOneToolSet load_dotenv () account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" def langgraph_tool_node () -> None : Demonstrate basic LangGraph integration with StackOne tools. toolset = StackOneToolSet () tools = toolset . get_tools ( \"hris_*\" , account_id = account_id ) # Verify we have the tools we need assert len ( tools ) > 0 , \"Expected at least one HRIS tool\" employee_tool = tools . get_tool ( \"hris_get_employee\" ) assert employee_tool is not None , \"Expected hris_get_employee tool\" # TODO: Add LangGraph specific integration # For now, just verify the tools are properly configured langchain_tools = tools . to_langchain () assert len ( langchain_tools ) > 0 , \"Expected LangChain tools\" assert all ( hasattr ( tool , \"_run\" ) for tool in langchain_tools ), \"Expected all tools to have _run method\" if __name__ == \"__main__\" : langgraph_tool_node ()","title":"Langgraph Tool Node"},{"location":"mcp-server/","text":"Mcp Server # This package can also be used as a Model Context Protocol (MCP) server. To add this server to and MCP client like Claude Code, use: # install the package uv pip install stackone-ai # add the server to Claude Code claude mcp add stackone uv stackmcp [ \"--api-key\" , \"<your-api-key>\" ] This implementation is a work in progress and will likely change dramatically in the near future.","title":"Mcp Server"},{"location":"mcp-server/#mcp-server","text":"This package can also be used as a Model Context Protocol (MCP) server. To add this server to and MCP client like Claude Code, use: # install the package uv pip install stackone-ai # add the server to Claude Code claude mcp add stackone uv stackmcp [ \"--api-key\" , \"<your-api-key>\" ] This implementation is a work in progress and will likely change dramatically in the near future.","title":"Mcp Server"},{"location":"meta-tools-example/","text":"Meta Tools Example # #!/usr/bin/env python Example demonstrating meta tools for dynamic tool discovery and execution. Meta tools allow AI agents to search for relevant tools based on natural language queries and execute them dynamically without hardcoding tool names. import os from dotenv import load_dotenv from stackone_ai import StackOneToolSet # Load environment variables load_dotenv () def example_meta_tools_basic (): Basic example of using meta tools for tool discovery print ( \"\ud83d\udd0d Example 1: Dynamic tool discovery \\n \" ) # Initialize StackOne toolset toolset = StackOneToolSet () # Get all available tools (you can also use pattern like \"hris_*\") all_tools = toolset . get_tools ( \"hris_*\" ) print ( f \"Total HRIS tools available: { len ( all_tools ) } \" ) # Get meta tools for dynamic discovery meta_tools = all_tools . meta_tools () # Get the filter tool to search for relevant tools filter_tool = meta_tools . get_tool ( \"meta_filter_relevant_tools\" ) if filter_tool : # Search for employee management tools result = filter_tool . call ( query = \"manage employees create update list\" , limit = 5 , minScore = 0.0 ) print ( \"Found relevant tools:\" ) for tool in result . get ( \"tools\" , []): print ( f \" - { tool [ 'name' ] } (score: { tool [ 'score' ] : .2f } ): { tool [ 'description' ] } \" ) print () def example_meta_tools_with_execution (): Example of discovering and executing tools dynamically print ( \"\ud83d\ude80 Example 2: Dynamic tool execution \\n \" ) # Initialize toolset toolset = StackOneToolSet () # Get all tools all_tools = toolset . get_tools () meta_tools = all_tools . meta_tools () # Step 1: Search for relevant tools filter_tool = meta_tools . get_tool ( \"meta_filter_relevant_tools\" ) execute_tool = meta_tools . get_tool ( \"meta_execute_tool\" ) if filter_tool and execute_tool : # Find tools for listing employees search_result = filter_tool . call ( query = \"list all employees\" , limit = 1 ) tools_found = search_result . get ( \"tools\" , []) if tools_found : best_tool = tools_found [ 0 ] print ( f \"Best matching tool: { best_tool [ 'name' ] } \" ) print ( f \"Description: { best_tool [ 'description' ] } \" ) print ( f \"Relevance score: { best_tool [ 'score' ] : .2f } \" ) # Step 2: Execute the found tool try : print ( f \" \\n Executing { best_tool [ 'name' ] } ...\" ) result = execute_tool . call ( toolName = best_tool [ \"name\" ], params = { \"limit\" : 5 }) print ( f \"Execution result: { result } \" ) except Exception as e : print ( f \"Execution failed (expected in example): { e } \" ) print () def example_tool_calling (): Example of the new tool calling functionality print ( \"\ud83d\udcde Example 3: Tool calling functionality \\n \" ) # Initialize toolset toolset = StackOneToolSet () # Get a specific tool tool = toolset . get_tool ( \"hris_list_employees\" ) if tool : print ( f \"Tool: { tool . name } \" ) print ( f \"Description: { tool . description } \" ) # New calling methods try : # Method 1: Call with keyword arguments result = tool . call ( limit = 10 , page = 1 ) print ( f \"Called with kwargs: { result } \" ) except Exception as e : print ( f \"Call with kwargs (expected to fail in example): { e } \" ) try : # Method 2: Call with dictionary result = tool . call ({ \"limit\" : 10 , \"page\" : 1 }) print ( f \"Called with dict: { result } \" ) except Exception as e : print ( f \"Call with dict (expected to fail in example): { e } \" ) print () def example_with_openai (): Example of using meta tools with OpenAI print ( \"\ud83e\udd16 Example 4: Using meta tools with OpenAI \\n \" ) try : from openai import OpenAI # Initialize OpenAI client client = OpenAI () # Initialize StackOne toolset toolset = StackOneToolSet () # Get HRIS tools and their meta tools hris_tools = toolset . get_tools ( \"hris_*\" ) meta_tools = hris_tools . meta_tools () # Convert to OpenAI format openai_tools = meta_tools . to_openai () # Create a chat completion with meta tools response = client . chat . completions . create ( model = \"gpt-4\" , messages = [ { \"role\" : \"system\" , \"content\" : \"You are an HR assistant. Use meta_filter_relevant_tools to find appropriate tools, then meta_execute_tool to execute them.\" , }, { \"role\" : \"user\" , \"content\" : \"Can you help me find tools for managing employee records?\" }, ], tools = openai_tools , tool_choice = \"auto\" , ) print ( \"OpenAI Response:\" , response . choices [ 0 ] . message . content ) if response . choices [ 0 ] . message . tool_calls : print ( \" \\n Tool calls made:\" ) for tool_call in response . choices [ 0 ] . message . tool_calls : print ( f \" - { tool_call . function . name } \" ) except ImportError : print ( \"OpenAI library not installed. Install with: pip install openai\" ) except Exception as e : print ( f \"OpenAI example failed: { e } \" ) print () def example_with_langchain (): Example of using tools with LangChain print ( \"\ud83d\udd17 Example 5: Using tools with LangChain \\n \" ) try : from langchain.agents import AgentExecutor , create_tool_calling_agent from langchain_core.prompts import ChatPromptTemplate from langchain_openai import ChatOpenAI # Initialize StackOne toolset toolset = StackOneToolSet () # Get tools and convert to LangChain format tools = toolset . get_tools ( \"hris_list_*\" ) langchain_tools = tools . to_langchain () # Get meta tools as well meta_tools = tools . meta_tools () langchain_meta_tools = meta_tools . to_langchain () # Combine all tools all_langchain_tools = list ( langchain_tools ) + list ( langchain_meta_tools ) print ( f \"Available tools for LangChain: { len ( all_langchain_tools ) } \" ) for tool in all_langchain_tools : print ( f \" - { tool . name } : { tool . description } \" ) # Create LangChain agent llm = ChatOpenAI ( model = \"gpt-4\" , temperature = 0 ) prompt = ChatPromptTemplate . from_messages ( [ ( \"system\" , \"You are an HR assistant. Use the meta tools to discover and execute relevant tools.\" , ), ( \"human\" , \" {input} \" ), ( \"placeholder\" , \" {agent_scratchpad} \" ), ] ) agent = create_tool_calling_agent ( llm , all_langchain_tools , prompt ) agent_executor = AgentExecutor ( agent = agent , tools = all_langchain_tools , verbose = True ) # Run the agent result = agent_executor . invoke ({ \"input\" : \"Find tools that can list employee data\" }) print ( f \" \\n Agent result: { result [ 'output' ] } \" ) except ImportError as e : print ( f \"LangChain dependencies not installed: { e } \" ) print ( \"Install with: pip install langchain-openai\" ) except Exception as e : print ( f \"LangChain example failed: { e } \" ) print () def main (): Run all examples print ( \"=\" * 60 ) print ( \"StackOne AI SDK - Meta Tools & Tool Calling Examples\" ) print ( \"=\" * 60 ) print () # Basic examples that work without external APIs example_meta_tools_basic () example_meta_tools_with_execution () example_tool_calling () # Examples that require OpenAI API if os . getenv ( \"OPENAI_API_KEY\" ): example_with_openai () example_with_langchain () else : print ( \"\u2139\ufe0f Set OPENAI_API_KEY to run OpenAI and LangChain examples \\n \" ) print ( \"=\" * 60 ) print ( \"Examples completed!\" ) print ( \"=\" * 60 ) if __name__ == \"__main__\" : main ()","title":"Meta Tools Example"},{"location":"meta-tools-example/#meta-tools-example","text":"#!/usr/bin/env python Example demonstrating meta tools for dynamic tool discovery and execution. Meta tools allow AI agents to search for relevant tools based on natural language queries and execute them dynamically without hardcoding tool names. import os from dotenv import load_dotenv from stackone_ai import StackOneToolSet # Load environment variables load_dotenv () def example_meta_tools_basic (): Basic example of using meta tools for tool discovery print ( \"\ud83d\udd0d Example 1: Dynamic tool discovery \\n \" ) # Initialize StackOne toolset toolset = StackOneToolSet () # Get all available tools (you can also use pattern like \"hris_*\") all_tools = toolset . get_tools ( \"hris_*\" ) print ( f \"Total HRIS tools available: { len ( all_tools ) } \" ) # Get meta tools for dynamic discovery meta_tools = all_tools . meta_tools () # Get the filter tool to search for relevant tools filter_tool = meta_tools . get_tool ( \"meta_filter_relevant_tools\" ) if filter_tool : # Search for employee management tools result = filter_tool . call ( query = \"manage employees create update list\" , limit = 5 , minScore = 0.0 ) print ( \"Found relevant tools:\" ) for tool in result . get ( \"tools\" , []): print ( f \" - { tool [ 'name' ] } (score: { tool [ 'score' ] : .2f } ): { tool [ 'description' ] } \" ) print () def example_meta_tools_with_execution (): Example of discovering and executing tools dynamically print ( \"\ud83d\ude80 Example 2: Dynamic tool execution \\n \" ) # Initialize toolset toolset = StackOneToolSet () # Get all tools all_tools = toolset . get_tools () meta_tools = all_tools . meta_tools () # Step 1: Search for relevant tools filter_tool = meta_tools . get_tool ( \"meta_filter_relevant_tools\" ) execute_tool = meta_tools . get_tool ( \"meta_execute_tool\" ) if filter_tool and execute_tool : # Find tools for listing employees search_result = filter_tool . call ( query = \"list all employees\" , limit = 1 ) tools_found = search_result . get ( \"tools\" , []) if tools_found : best_tool = tools_found [ 0 ] print ( f \"Best matching tool: { best_tool [ 'name' ] } \" ) print ( f \"Description: { best_tool [ 'description' ] } \" ) print ( f \"Relevance score: { best_tool [ 'score' ] : .2f } \" ) # Step 2: Execute the found tool try : print ( f \" \\n Executing { best_tool [ 'name' ] } ...\" ) result = execute_tool . call ( toolName = best_tool [ \"name\" ], params = { \"limit\" : 5 }) print ( f \"Execution result: { result } \" ) except Exception as e : print ( f \"Execution failed (expected in example): { e } \" ) print () def example_tool_calling (): Example of the new tool calling functionality print ( \"\ud83d\udcde Example 3: Tool calling functionality \\n \" ) # Initialize toolset toolset = StackOneToolSet () # Get a specific tool tool = toolset . get_tool ( \"hris_list_employees\" ) if tool : print ( f \"Tool: { tool . name } \" ) print ( f \"Description: { tool . description } \" ) # New calling methods try : # Method 1: Call with keyword arguments result = tool . call ( limit = 10 , page = 1 ) print ( f \"Called with kwargs: { result } \" ) except Exception as e : print ( f \"Call with kwargs (expected to fail in example): { e } \" ) try : # Method 2: Call with dictionary result = tool . call ({ \"limit\" : 10 , \"page\" : 1 }) print ( f \"Called with dict: { result } \" ) except Exception as e : print ( f \"Call with dict (expected to fail in example): { e } \" ) print () def example_with_openai (): Example of using meta tools with OpenAI print ( \"\ud83e\udd16 Example 4: Using meta tools with OpenAI \\n \" ) try : from openai import OpenAI # Initialize OpenAI client client = OpenAI () # Initialize StackOne toolset toolset = StackOneToolSet () # Get HRIS tools and their meta tools hris_tools = toolset . get_tools ( \"hris_*\" ) meta_tools = hris_tools . meta_tools () # Convert to OpenAI format openai_tools = meta_tools . to_openai () # Create a chat completion with meta tools response = client . chat . completions . create ( model = \"gpt-4\" , messages = [ { \"role\" : \"system\" , \"content\" : \"You are an HR assistant. Use meta_filter_relevant_tools to find appropriate tools, then meta_execute_tool to execute them.\" , }, { \"role\" : \"user\" , \"content\" : \"Can you help me find tools for managing employee records?\" }, ], tools = openai_tools , tool_choice = \"auto\" , ) print ( \"OpenAI Response:\" , response . choices [ 0 ] . message . content ) if response . choices [ 0 ] . message . tool_calls : print ( \" \\n Tool calls made:\" ) for tool_call in response . choices [ 0 ] . message . tool_calls : print ( f \" - { tool_call . function . name } \" ) except ImportError : print ( \"OpenAI library not installed. Install with: pip install openai\" ) except Exception as e : print ( f \"OpenAI example failed: { e } \" ) print () def example_with_langchain (): Example of using tools with LangChain print ( \"\ud83d\udd17 Example 5: Using tools with LangChain \\n \" ) try : from langchain.agents import AgentExecutor , create_tool_calling_agent from langchain_core.prompts import ChatPromptTemplate from langchain_openai import ChatOpenAI # Initialize StackOne toolset toolset = StackOneToolSet () # Get tools and convert to LangChain format tools = toolset . get_tools ( \"hris_list_*\" ) langchain_tools = tools . to_langchain () # Get meta tools as well meta_tools = tools . meta_tools () langchain_meta_tools = meta_tools . to_langchain () # Combine all tools all_langchain_tools = list ( langchain_tools ) + list ( langchain_meta_tools ) print ( f \"Available tools for LangChain: { len ( all_langchain_tools ) } \" ) for tool in all_langchain_tools : print ( f \" - { tool . name } : { tool . description } \" ) # Create LangChain agent llm = ChatOpenAI ( model = \"gpt-4\" , temperature = 0 ) prompt = ChatPromptTemplate . from_messages ( [ ( \"system\" , \"You are an HR assistant. Use the meta tools to discover and execute relevant tools.\" , ), ( \"human\" , \" {input} \" ), ( \"placeholder\" , \" {agent_scratchpad} \" ), ] ) agent = create_tool_calling_agent ( llm , all_langchain_tools , prompt ) agent_executor = AgentExecutor ( agent = agent , tools = all_langchain_tools , verbose = True ) # Run the agent result = agent_executor . invoke ({ \"input\" : \"Find tools that can list employee data\" }) print ( f \" \\n Agent result: { result [ 'output' ] } \" ) except ImportError as e : print ( f \"LangChain dependencies not installed: { e } \" ) print ( \"Install with: pip install langchain-openai\" ) except Exception as e : print ( f \"LangChain example failed: { e } \" ) print () def main (): Run all examples print ( \"=\" * 60 ) print ( \"StackOne AI SDK - Meta Tools & Tool Calling Examples\" ) print ( \"=\" * 60 ) print () # Basic examples that work without external APIs example_meta_tools_basic () example_meta_tools_with_execution () example_tool_calling () # Examples that require OpenAI API if os . getenv ( \"OPENAI_API_KEY\" ): example_with_openai () example_with_langchain () else : print ( \"\u2139\ufe0f Set OPENAI_API_KEY to run OpenAI and LangChain examples \\n \" ) print ( \"=\" * 60 ) print ( \"Examples completed!\" ) print ( \"=\" * 60 ) if __name__ == \"__main__\" : main ()","title":"Meta Tools Example"},{"location":"openai-integration/","text":"Openai Integration # This example demonstrates how to use StackOne tools with OpenAI's function calling. This example is runnable with the following command: uv run examples/openai_integration.py You can find out more about the OpenAI Function Calling API format here . from dotenv import load_dotenv from openai import OpenAI from stackone_ai import StackOneToolSet load_dotenv () account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" def handle_tool_calls ( tools , tool_calls ) -> list [ dict ]: results = [] for tool_call in tool_calls : tool = tools . get_tool ( tool_call . function . name ) if tool : results . append ( tool . execute ( tool_call . function . arguments )) return results def openai_integration () -> None : client = OpenAI () toolset = StackOneToolSet () # Filter tools to only the ones we need to avoid context window limits tools = toolset . get_tools ( [ \"hris_get_employee\" , \"hris_list_employee_employments\" , \"hris_get_employee_employment\" , ], account_id = account_id , ) openai_tools = tools . to_openai () messages = [ { \"role\" : \"system\" , \"content\" : \"You are a helpful HR assistant.\" }, { \"role\" : \"user\" , \"content\" : f \"Can you get me information about employee with ID: { employee_id } ?\" , }, ] response = client . chat . completions . create ( model = \"gpt-4o-mini\" , messages = messages , tools = openai_tools , tool_choice = \"auto\" , ) # Verify we got a response with tool calls assert response . choices [ 0 ] . message . tool_calls is not None , \"Expected tool calls in response\" # Handle the tool calls and verify results results = handle_tool_calls ( tools , response . choices [ 0 ] . message . tool_calls ) assert results is not None and len ( results ) > 0 , \"Expected tool call results\" assert \"data\" in results [ 0 ], \"Expected data in tool call result\" # Verify we can continue the conversation with the results messages . extend ( [ { \"role\" : \"assistant\" , \"content\" : None , \"tool_calls\" : response . choices [ 0 ] . message . tool_calls }, { \"role\" : \"tool\" , \"tool_call_id\" : response . choices [ 0 ] . message . tool_calls [ 0 ] . id , \"content\" : str ( results [ 0 ]), }, ] ) # Verify the final response final_response = client . chat . completions . create ( model = \"gpt-4o-mini\" , messages = messages , tools = openai_tools , tool_choice = \"auto\" , ) assert final_response . choices [ 0 ] . message . content is not None , \"Expected final response content\" if __name__ == \"__main__\" : openai_integration ()","title":"OpenAI"},{"location":"openai-integration/#openai-integration","text":"This example demonstrates how to use StackOne tools with OpenAI's function calling. This example is runnable with the following command: uv run examples/openai_integration.py You can find out more about the OpenAI Function Calling API format here . from dotenv import load_dotenv from openai import OpenAI from stackone_ai import StackOneToolSet load_dotenv () account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" def handle_tool_calls ( tools , tool_calls ) -> list [ dict ]: results = [] for tool_call in tool_calls : tool = tools . get_tool ( tool_call . function . name ) if tool : results . append ( tool . execute ( tool_call . function . arguments )) return results def openai_integration () -> None : client = OpenAI () toolset = StackOneToolSet () # Filter tools to only the ones we need to avoid context window limits tools = toolset . get_tools ( [ \"hris_get_employee\" , \"hris_list_employee_employments\" , \"hris_get_employee_employment\" , ], account_id = account_id , ) openai_tools = tools . to_openai () messages = [ { \"role\" : \"system\" , \"content\" : \"You are a helpful HR assistant.\" }, { \"role\" : \"user\" , \"content\" : f \"Can you get me information about employee with ID: { employee_id } ?\" , }, ] response = client . chat . completions . create ( model = \"gpt-4o-mini\" , messages = messages , tools = openai_tools , tool_choice = \"auto\" , ) # Verify we got a response with tool calls assert response . choices [ 0 ] . message . tool_calls is not None , \"Expected tool calls in response\" # Handle the tool calls and verify results results = handle_tool_calls ( tools , response . choices [ 0 ] . message . tool_calls ) assert results is not None and len ( results ) > 0 , \"Expected tool call results\" assert \"data\" in results [ 0 ], \"Expected data in tool call result\" # Verify we can continue the conversation with the results messages . extend ( [ { \"role\" : \"assistant\" , \"content\" : None , \"tool_calls\" : response . choices [ 0 ] . message . tool_calls }, { \"role\" : \"tool\" , \"tool_call_id\" : response . choices [ 0 ] . message . tool_calls [ 0 ] . id , \"content\" : str ( results [ 0 ]), }, ] ) # Verify the final response final_response = client . chat . completions . create ( model = \"gpt-4o-mini\" , messages = messages , tools = openai_tools , tool_choice = \"auto\" , ) assert final_response . choices [ 0 ] . message . content is not None , \"Expected final response content\" if __name__ == \"__main__\" : openai_integration ()","title":"Openai Integration"},{"location":"stackone-account-ids/","text":"Stackone Account Ids # Handling StackOne account IDs with the StackOne Tools. uv run examples/stackone_account_ids.py from dotenv import load_dotenv from stackone_ai import StackOneToolSet load_dotenv () def stackone_account_ids (): toolset = StackOneToolSet () Set the account ID whilst getting tools. tools = toolset . get_tools ( \"hris_*\" , account_id = \"test_id\" ) You can over write the account ID on fetched tools. tools . set_account_id ( \"a_different_id\" ) employee_tool = tools . get_tool ( \"hris_get_employee\" ) assert employee_tool is not None You can even set the account ID on a per-tool basis. employee_tool . set_account_id ( \"again_another_id\" ) assert employee_tool . get_account_id () == \"again_another_id\" if __name__ == \"__main__\" : stackone_account_ids ()","title":"StackOne Account IDs"},{"location":"stackone-account-ids/#stackone-account-ids","text":"Handling StackOne account IDs with the StackOne Tools. uv run examples/stackone_account_ids.py from dotenv import load_dotenv from stackone_ai import StackOneToolSet load_dotenv () def stackone_account_ids (): toolset = StackOneToolSet () Set the account ID whilst getting tools. tools = toolset . get_tools ( \"hris_*\" , account_id = \"test_id\" ) You can over write the account ID on fetched tools. tools . set_account_id ( \"a_different_id\" ) employee_tool = tools . get_tool ( \"hris_get_employee\" ) assert employee_tool is not None You can even set the account ID on a per-tool basis. employee_tool . set_account_id ( \"again_another_id\" ) assert employee_tool . get_account_id () == \"again_another_id\" if __name__ == \"__main__\" : stackone_account_ids ()","title":"Stackone Account Ids"}]}