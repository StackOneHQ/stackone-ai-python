{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"StackOne AI SDK # StackOne AI SDK provides an AI-friendly interface for accessing various SaaS tools through the StackOne Unified API. This SDK is available on PyPI for python projects. There is a node version in the works. Installation # # Using uv uv add stackone-ai # Using pip pip install stackone-ai How to use these docs # All examples are complete and runnable. We use uv for easy python dependency management. Install uv: curl -LsSf https://astral.sh/uv/install.sh | sh To run this example, clone the repo, install the dependencies (one-time setup) and run the script: git clone https://github.com/stackoneHQ/stackone-ai-python.git cd stackone-ai-python # Install dependencies uv sync --all-extras # Run the example uv run examples/index.py Authentication # Set the STACKONE_API_KEY environment variable: export STACKONE_API_KEY = <your-api-key> or load from a .env file: from dotenv import load_dotenv load_dotenv () Account IDs # StackOne uses account IDs to identify different integrations. See the example stackone-account-ids.md for more details. This example will hardcode the account ID: account_id = \"45072196112816593343\" Quickstart # from stackone_ai import StackOneToolSet def quickstart (): toolset = StackOneToolSet () # Get all HRIS-related tools using MCP-backed fetch_tools() tools = toolset . fetch_tools ( actions = [ \"hris_*\" ], account_ids = [ account_id ]) # Use a specific tool employee_tool = tools . get_tool ( \"hris_list_employees\" ) assert employee_tool is not None employees = employee_tool . execute () assert employees is not None if __name__ == \"__main__\" : quickstart () Next Steps # Check out some more documentation: StackOne Account IDs Error Handling Available Tools File Uploads Or get started with an integration: OpenAI LangChain CrewAI LangGraph","title":"Home"},{"location":"#stackone-ai-sdk","text":"StackOne AI SDK provides an AI-friendly interface for accessing various SaaS tools through the StackOne Unified API. This SDK is available on PyPI for python projects. There is a node version in the works.","title":"StackOne AI SDK"},{"location":"#installation","text":"# Using uv uv add stackone-ai # Using pip pip install stackone-ai","title":"Installation"},{"location":"#how-to-use-these-docs","text":"All examples are complete and runnable. We use uv for easy python dependency management. Install uv: curl -LsSf https://astral.sh/uv/install.sh | sh To run this example, clone the repo, install the dependencies (one-time setup) and run the script: git clone https://github.com/stackoneHQ/stackone-ai-python.git cd stackone-ai-python # Install dependencies uv sync --all-extras # Run the example uv run examples/index.py","title":"How to use these docs"},{"location":"#authentication","text":"Set the STACKONE_API_KEY environment variable: export STACKONE_API_KEY = <your-api-key> or load from a .env file: from dotenv import load_dotenv load_dotenv ()","title":"Authentication"},{"location":"#account-ids","text":"StackOne uses account IDs to identify different integrations. See the example stackone-account-ids.md for more details. This example will hardcode the account ID: account_id = \"45072196112816593343\"","title":"Account IDs"},{"location":"#quickstart","text":"from stackone_ai import StackOneToolSet def quickstart (): toolset = StackOneToolSet () # Get all HRIS-related tools using MCP-backed fetch_tools() tools = toolset . fetch_tools ( actions = [ \"hris_*\" ], account_ids = [ account_id ]) # Use a specific tool employee_tool = tools . get_tool ( \"hris_list_employees\" ) assert employee_tool is not None employees = employee_tool . execute () assert employees is not None if __name__ == \"__main__\" : quickstart ()","title":"Quickstart"},{"location":"#next-steps","text":"Check out some more documentation: StackOne Account IDs Error Handling Available Tools File Uploads Or get started with an integration: OpenAI LangChain CrewAI LangGraph","title":"Next Steps"},{"location":"crewai-integration/","text":"Crewai Integration # This example demonstrates how to use StackOne tools with CrewAI. CrewAI uses LangChain tools natively. uv run examples/crewai_integration.py from crewai import Agent , Crew , Task from stackone_ai import StackOneToolSet account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" def crewai_integration (): toolset = StackOneToolSet () tools = toolset . fetch_tools ( actions = [ \"hris_*\" ], account_ids = [ account_id ]) # CrewAI uses LangChain tools natively langchain_tools = tools . to_langchain () assert len ( langchain_tools ) > 0 , \"Expected at least one LangChain tool\" for tool in langchain_tools : assert hasattr ( tool , \"name\" ), \"Expected tool to have name\" assert hasattr ( tool , \"description\" ), \"Expected tool to have description\" assert hasattr ( tool , \"_run\" ), \"Expected tool to have _run method\" agent = Agent ( role = \"HR Manager\" , goal = f \"What is the employee with the id { employee_id } ?\" , backstory = \"With over 10 years of experience in HR and employee management, \" \"you excel at finding patterns in complex datasets.\" , llm = \"gpt-4o-mini\" , tools = langchain_tools , max_iter = 2 , ) task = Task ( description = \"What is the employee with the id c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA?\" , agent = agent , expected_output = \"A JSON object containing the employee's information\" , ) crew = Crew ( agents = [ agent ], tasks = [ task ]) result = crew . kickoff () assert result is not None , \"Expected result to be returned\" if __name__ == \"__main__\" : crewai_integration ()","title":"CrewAI"},{"location":"crewai-integration/#crewai-integration","text":"This example demonstrates how to use StackOne tools with CrewAI. CrewAI uses LangChain tools natively. uv run examples/crewai_integration.py from crewai import Agent , Crew , Task from stackone_ai import StackOneToolSet account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" def crewai_integration (): toolset = StackOneToolSet () tools = toolset . fetch_tools ( actions = [ \"hris_*\" ], account_ids = [ account_id ]) # CrewAI uses LangChain tools natively langchain_tools = tools . to_langchain () assert len ( langchain_tools ) > 0 , \"Expected at least one LangChain tool\" for tool in langchain_tools : assert hasattr ( tool , \"name\" ), \"Expected tool to have name\" assert hasattr ( tool , \"description\" ), \"Expected tool to have description\" assert hasattr ( tool , \"_run\" ), \"Expected tool to have _run method\" agent = Agent ( role = \"HR Manager\" , goal = f \"What is the employee with the id { employee_id } ?\" , backstory = \"With over 10 years of experience in HR and employee management, \" \"you excel at finding patterns in complex datasets.\" , llm = \"gpt-4o-mini\" , tools = langchain_tools , max_iter = 2 , ) task = Task ( description = \"What is the employee with the id c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA?\" , agent = agent , expected_output = \"A JSON object containing the employee's information\" , ) crew = Crew ( agents = [ agent ], tasks = [ task ]) result = crew . kickoff () assert result is not None , \"Expected result to be returned\" if __name__ == \"__main__\" : crewai_integration ()","title":"Crewai Integration"},{"location":"file-uploads/","text":"File Uploads # Example demonstrating file upload functionality using StackOne. Shows how to upload an employee document using an HRIS integration. This example is runnable with the following command: uv run examples/file_upload_example.py import base64 import tempfile from pathlib import Path from dotenv import load_dotenv from stackone_ai import StackOneToolSet load_dotenv () account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" Resume content # This is a sample resume content that will be uploaded using the hris_upload_employee_document tool. resume_content = \"\"\" JOHN DOE Software Engineer EXPERIENCE Senior Developer - Tech Corp 2020-Present - Led development of core features - Managed team of 5 engineers EDUCATION BS Computer Science University of Technology 2016-2020 \"\"\" Upload employee document # This function uploads a resume using the hris_upload_employee_document tool. def upload_employee_document () -> None : with tempfile . TemporaryDirectory () as temp_dir : resume_file = Path ( temp_dir ) / \"resume.pdf\" resume_file . write_text ( resume_content ) toolset = StackOneToolSet () tools = toolset . fetch_tools ( actions = [ \"hris_*\" ], account_ids = [ account_id ]) upload_tool = tools . get_tool ( \"hris_upload_employee_document\" ) assert upload_tool is not None with open ( resume_file , \"rb\" ) as f : file_content = base64 . b64encode ( f . read ()) . decode () upload_params = { \"x-account-id\" : account_id , \"id\" : employee_id , \"name\" : \"resume\" , \"content\" : file_content , \"category\" : { \"value\" : \"shared\" }, \"file_format\" : { \"value\" : \"txt\" }, } result = upload_tool . execute ( upload_params ) assert result is not None assert result . get ( \"message\" ) == \"File uploaded successfully\" if __name__ == \"__main__\" : upload_employee_document ()","title":"File Uploads"},{"location":"file-uploads/#file-uploads","text":"Example demonstrating file upload functionality using StackOne. Shows how to upload an employee document using an HRIS integration. This example is runnable with the following command: uv run examples/file_upload_example.py import base64 import tempfile from pathlib import Path from dotenv import load_dotenv from stackone_ai import StackOneToolSet load_dotenv () account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\"","title":"File Uploads"},{"location":"file-uploads/#resume-content","text":"This is a sample resume content that will be uploaded using the hris_upload_employee_document tool. resume_content = \"\"\" JOHN DOE Software Engineer EXPERIENCE Senior Developer - Tech Corp 2020-Present - Led development of core features - Managed team of 5 engineers EDUCATION BS Computer Science University of Technology 2016-2020 \"\"\"","title":"Resume content"},{"location":"file-uploads/#upload-employee-document","text":"This function uploads a resume using the hris_upload_employee_document tool. def upload_employee_document () -> None : with tempfile . TemporaryDirectory () as temp_dir : resume_file = Path ( temp_dir ) / \"resume.pdf\" resume_file . write_text ( resume_content ) toolset = StackOneToolSet () tools = toolset . fetch_tools ( actions = [ \"hris_*\" ], account_ids = [ account_id ]) upload_tool = tools . get_tool ( \"hris_upload_employee_document\" ) assert upload_tool is not None with open ( resume_file , \"rb\" ) as f : file_content = base64 . b64encode ( f . read ()) . decode () upload_params = { \"x-account-id\" : account_id , \"id\" : employee_id , \"name\" : \"resume\" , \"content\" : file_content , \"category\" : { \"value\" : \"shared\" }, \"file_format\" : { \"value\" : \"txt\" }, } result = upload_tool . execute ( upload_params ) assert result is not None assert result . get ( \"message\" ) == \"File uploaded successfully\" if __name__ == \"__main__\" : upload_employee_document ()","title":"Upload employee document"},{"location":"langchain-integration/","text":"Langchain Integration # This example demonstrates how to use StackOne tools with LangChain. uv run examples/langchain_integration.py from dotenv import load_dotenv from langchain_openai import ChatOpenAI from stackone_ai import StackOneToolSet load_dotenv () account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" def langchain_integration () -> None : toolset = StackOneToolSet () tools = toolset . fetch_tools ( actions = [ \"hris_*\" ], account_ids = [ account_id ]) # Convert to LangChain format and verify langchain_tools = tools . to_langchain () assert len ( langchain_tools ) > 0 , \"Expected at least one LangChain tool\" # Verify tool structure for tool in langchain_tools : assert hasattr ( tool , \"name\" ), \"Expected tool to have name\" assert hasattr ( tool , \"description\" ), \"Expected tool to have description\" assert hasattr ( tool , \"_run\" ), \"Expected tool to have _run method\" assert hasattr ( tool , \"args_schema\" ), \"Expected tool to have args_schema\" # Create model with tools model = ChatOpenAI ( model = \"gpt-4o-mini\" ) model_with_tools = model . bind_tools ( langchain_tools ) result = model_with_tools . invoke ( f \"Can you get me information about employee with ID: { employee_id } ?\" ) assert result . tool_calls is not None for tool_call in result . tool_calls : tool = tools . get_tool ( tool_call [ \"name\" ]) if tool : result = tool . execute ( tool_call [ \"args\" ]) assert result is not None assert result . get ( \"data\" ) is not None if __name__ == \"__main__\" : langchain_integration ()","title":"LangChain"},{"location":"langchain-integration/#langchain-integration","text":"This example demonstrates how to use StackOne tools with LangChain. uv run examples/langchain_integration.py from dotenv import load_dotenv from langchain_openai import ChatOpenAI from stackone_ai import StackOneToolSet load_dotenv () account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" def langchain_integration () -> None : toolset = StackOneToolSet () tools = toolset . fetch_tools ( actions = [ \"hris_*\" ], account_ids = [ account_id ]) # Convert to LangChain format and verify langchain_tools = tools . to_langchain () assert len ( langchain_tools ) > 0 , \"Expected at least one LangChain tool\" # Verify tool structure for tool in langchain_tools : assert hasattr ( tool , \"name\" ), \"Expected tool to have name\" assert hasattr ( tool , \"description\" ), \"Expected tool to have description\" assert hasattr ( tool , \"_run\" ), \"Expected tool to have _run method\" assert hasattr ( tool , \"args_schema\" ), \"Expected tool to have args_schema\" # Create model with tools model = ChatOpenAI ( model = \"gpt-4o-mini\" ) model_with_tools = model . bind_tools ( langchain_tools ) result = model_with_tools . invoke ( f \"Can you get me information about employee with ID: { employee_id } ?\" ) assert result . tool_calls is not None for tool_call in result . tool_calls : tool = tools . get_tool ( tool_call [ \"name\" ]) if tool : result = tool . execute ( tool_call [ \"args\" ]) assert result is not None assert result . get ( \"data\" ) is not None if __name__ == \"__main__\" : langchain_integration ()","title":"Langchain Integration"},{"location":"mcp-server/","text":"Mcp Server # This package can also be used as a Model Context Protocol (MCP) server. To add this server to and MCP client like Claude Code, use: # install the package uv pip install stackone-ai # add the server to Claude Code claude mcp add stackone uv stackmcp [ \"--api-key\" , \"<your-api-key>\" ] This implementation is a work in progress and will likely change dramatically in the near future.","title":"Mcp Server"},{"location":"mcp-server/#mcp-server","text":"This package can also be used as a Model Context Protocol (MCP) server. To add this server to and MCP client like Claude Code, use: # install the package uv pip install stackone-ai # add the server to Claude Code claude mcp add stackone uv stackmcp [ \"--api-key\" , \"<your-api-key>\" ] This implementation is a work in progress and will likely change dramatically in the near future.","title":"Mcp Server"},{"location":"meta-tools-example/","text":"Meta Tools Example # #!/usr/bin/env python Example demonstrating meta tools for dynamic tool discovery and execution. Meta tools allow AI agents to search for relevant tools based on natural language queries and execute them dynamically without hardcoding tool names. import os from dotenv import load_dotenv from stackone_ai import StackOneToolSet # Load environment variables load_dotenv () def example_meta_tools_basic (): Basic example of using meta tools for tool discovery print ( \"Example 1: Dynamic tool discovery \\n \" ) # Initialize StackOne toolset toolset = StackOneToolSet () # Get all available tools using MCP-backed fetch_tools() all_tools = toolset . fetch_tools ( actions = [ \"hris_*\" ]) print ( f \"Total HRIS tools available: { len ( all_tools ) } \" ) # Get meta tools for dynamic discovery meta_tools = all_tools . meta_tools () # Get the filter tool to search for relevant tools filter_tool = meta_tools . get_tool ( \"meta_search_tools\" ) if filter_tool : # Search for employee management tools result = filter_tool . call ( query = \"manage employees create update list\" , limit = 5 , minScore = 0.0 ) print ( \"Found relevant tools:\" ) for tool in result . get ( \"tools\" , []): print ( f \" - { tool [ 'name' ] } (score: { tool [ 'score' ] : .2f } ): { tool [ 'description' ] } \" ) print () def example_meta_tools_with_execution (): Example of discovering and executing tools dynamically print ( \"Example 2: Dynamic tool execution \\n \" ) # Initialize toolset toolset = StackOneToolSet () # Get all tools using MCP-backed fetch_tools() all_tools = toolset . fetch_tools () meta_tools = all_tools . meta_tools () # Step 1: Search for relevant tools filter_tool = meta_tools . get_tool ( \"meta_search_tools\" ) execute_tool = meta_tools . get_tool ( \"meta_execute_tool\" ) if filter_tool and execute_tool : # Find tools for listing employees search_result = filter_tool . call ( query = \"list all employees\" , limit = 1 ) tools_found = search_result . get ( \"tools\" , []) if tools_found : best_tool = tools_found [ 0 ] print ( f \"Best matching tool: { best_tool [ 'name' ] } \" ) print ( f \"Description: { best_tool [ 'description' ] } \" ) print ( f \"Relevance score: { best_tool [ 'score' ] : .2f } \" ) # Step 2: Execute the found tool try : print ( f \" \\n Executing { best_tool [ 'name' ] } ...\" ) result = execute_tool . call ( toolName = best_tool [ \"name\" ], params = { \"limit\" : 5 }) print ( f \"Execution result: { result } \" ) except Exception as e : print ( f \"Execution failed (expected in example): { e } \" ) print () def example_with_openai (): Example of using meta tools with OpenAI print ( \"Example 3: Using meta tools with OpenAI \\n \" ) try : from openai import OpenAI # Initialize OpenAI client client = OpenAI () # Initialize StackOne toolset toolset = StackOneToolSet () # Get HRIS tools and their meta tools using MCP-backed fetch_tools() hris_tools = toolset . fetch_tools ( actions = [ \"hris_*\" ]) meta_tools = hris_tools . meta_tools () # Convert to OpenAI format openai_tools = meta_tools . to_openai () # Create a chat completion with meta tools response = client . chat . completions . create ( model = \"gpt-4\" , messages = [ { \"role\" : \"system\" , \"content\" : \"You are an HR assistant. Use meta_search_tools to find appropriate tools, then meta_execute_tool to execute them.\" , }, { \"role\" : \"user\" , \"content\" : \"Can you help me find tools for managing employee records?\" }, ], tools = openai_tools , tool_choice = \"auto\" , ) print ( \"OpenAI Response:\" , response . choices [ 0 ] . message . content ) if response . choices [ 0 ] . message . tool_calls : print ( \" \\n Tool calls made:\" ) for tool_call in response . choices [ 0 ] . message . tool_calls : print ( f \" - { tool_call . function . name } \" ) except ImportError : print ( \"OpenAI library not installed. Install with: pip install openai\" ) except Exception as e : print ( f \"OpenAI example failed: { e } \" ) print () def example_with_langchain (): Example of using tools with LangChain print ( \"Example 4: Using tools with LangChain \\n \" ) try : from langchain.agents import AgentExecutor , create_tool_calling_agent from langchain_core.prompts import ChatPromptTemplate from langchain_openai import ChatOpenAI # Initialize StackOne toolset toolset = StackOneToolSet () # Get tools and convert to LangChain format using MCP-backed fetch_tools() tools = toolset . fetch_tools ( actions = [ \"hris_list_*\" ]) langchain_tools = tools . to_langchain () # Get meta tools as well meta_tools = tools . meta_tools () langchain_meta_tools = meta_tools . to_langchain () # Combine all tools all_langchain_tools = list ( langchain_tools ) + list ( langchain_meta_tools ) print ( f \"Available tools for LangChain: { len ( all_langchain_tools ) } \" ) for tool in all_langchain_tools : print ( f \" - { tool . name } : { tool . description } \" ) # Create LangChain agent llm = ChatOpenAI ( model = \"gpt-4\" , temperature = 0 ) prompt = ChatPromptTemplate . from_messages ( [ ( \"system\" , \"You are an HR assistant. Use the meta tools to discover and execute relevant tools.\" , ), ( \"human\" , \" {input} \" ), ( \"placeholder\" , \" {agent_scratchpad} \" ), ] ) agent = create_tool_calling_agent ( llm , all_langchain_tools , prompt ) agent_executor = AgentExecutor ( agent = agent , tools = all_langchain_tools , verbose = True ) # Run the agent result = agent_executor . invoke ({ \"input\" : \"Find tools that can list employee data\" }) print ( f \" \\n Agent result: { result [ 'output' ] } \" ) except ImportError as e : print ( f \"LangChain dependencies not installed: { e } \" ) print ( \"Install with: pip install langchain-openai\" ) except Exception as e : print ( f \"LangChain example failed: { e } \" ) print () def main (): Run all examples print ( \"=\" * 60 ) print ( \"StackOne AI SDK - Meta Tools Examples\" ) print ( \"=\" * 60 ) print () # Basic examples that work without external APIs example_meta_tools_basic () example_meta_tools_with_execution () # Examples that require OpenAI API if os . getenv ( \"OPENAI_API_KEY\" ): example_with_openai () example_with_langchain () else : print ( \"Set OPENAI_API_KEY to run OpenAI and LangChain examples \\n \" ) print ( \"=\" * 60 ) print ( \"Examples completed!\" ) print ( \"=\" * 60 ) if __name__ == \"__main__\" : main ()","title":"Meta Tools Example"},{"location":"meta-tools-example/#meta-tools-example","text":"#!/usr/bin/env python Example demonstrating meta tools for dynamic tool discovery and execution. Meta tools allow AI agents to search for relevant tools based on natural language queries and execute them dynamically without hardcoding tool names. import os from dotenv import load_dotenv from stackone_ai import StackOneToolSet # Load environment variables load_dotenv () def example_meta_tools_basic (): Basic example of using meta tools for tool discovery print ( \"Example 1: Dynamic tool discovery \\n \" ) # Initialize StackOne toolset toolset = StackOneToolSet () # Get all available tools using MCP-backed fetch_tools() all_tools = toolset . fetch_tools ( actions = [ \"hris_*\" ]) print ( f \"Total HRIS tools available: { len ( all_tools ) } \" ) # Get meta tools for dynamic discovery meta_tools = all_tools . meta_tools () # Get the filter tool to search for relevant tools filter_tool = meta_tools . get_tool ( \"meta_search_tools\" ) if filter_tool : # Search for employee management tools result = filter_tool . call ( query = \"manage employees create update list\" , limit = 5 , minScore = 0.0 ) print ( \"Found relevant tools:\" ) for tool in result . get ( \"tools\" , []): print ( f \" - { tool [ 'name' ] } (score: { tool [ 'score' ] : .2f } ): { tool [ 'description' ] } \" ) print () def example_meta_tools_with_execution (): Example of discovering and executing tools dynamically print ( \"Example 2: Dynamic tool execution \\n \" ) # Initialize toolset toolset = StackOneToolSet () # Get all tools using MCP-backed fetch_tools() all_tools = toolset . fetch_tools () meta_tools = all_tools . meta_tools () # Step 1: Search for relevant tools filter_tool = meta_tools . get_tool ( \"meta_search_tools\" ) execute_tool = meta_tools . get_tool ( \"meta_execute_tool\" ) if filter_tool and execute_tool : # Find tools for listing employees search_result = filter_tool . call ( query = \"list all employees\" , limit = 1 ) tools_found = search_result . get ( \"tools\" , []) if tools_found : best_tool = tools_found [ 0 ] print ( f \"Best matching tool: { best_tool [ 'name' ] } \" ) print ( f \"Description: { best_tool [ 'description' ] } \" ) print ( f \"Relevance score: { best_tool [ 'score' ] : .2f } \" ) # Step 2: Execute the found tool try : print ( f \" \\n Executing { best_tool [ 'name' ] } ...\" ) result = execute_tool . call ( toolName = best_tool [ \"name\" ], params = { \"limit\" : 5 }) print ( f \"Execution result: { result } \" ) except Exception as e : print ( f \"Execution failed (expected in example): { e } \" ) print () def example_with_openai (): Example of using meta tools with OpenAI print ( \"Example 3: Using meta tools with OpenAI \\n \" ) try : from openai import OpenAI # Initialize OpenAI client client = OpenAI () # Initialize StackOne toolset toolset = StackOneToolSet () # Get HRIS tools and their meta tools using MCP-backed fetch_tools() hris_tools = toolset . fetch_tools ( actions = [ \"hris_*\" ]) meta_tools = hris_tools . meta_tools () # Convert to OpenAI format openai_tools = meta_tools . to_openai () # Create a chat completion with meta tools response = client . chat . completions . create ( model = \"gpt-4\" , messages = [ { \"role\" : \"system\" , \"content\" : \"You are an HR assistant. Use meta_search_tools to find appropriate tools, then meta_execute_tool to execute them.\" , }, { \"role\" : \"user\" , \"content\" : \"Can you help me find tools for managing employee records?\" }, ], tools = openai_tools , tool_choice = \"auto\" , ) print ( \"OpenAI Response:\" , response . choices [ 0 ] . message . content ) if response . choices [ 0 ] . message . tool_calls : print ( \" \\n Tool calls made:\" ) for tool_call in response . choices [ 0 ] . message . tool_calls : print ( f \" - { tool_call . function . name } \" ) except ImportError : print ( \"OpenAI library not installed. Install with: pip install openai\" ) except Exception as e : print ( f \"OpenAI example failed: { e } \" ) print () def example_with_langchain (): Example of using tools with LangChain print ( \"Example 4: Using tools with LangChain \\n \" ) try : from langchain.agents import AgentExecutor , create_tool_calling_agent from langchain_core.prompts import ChatPromptTemplate from langchain_openai import ChatOpenAI # Initialize StackOne toolset toolset = StackOneToolSet () # Get tools and convert to LangChain format using MCP-backed fetch_tools() tools = toolset . fetch_tools ( actions = [ \"hris_list_*\" ]) langchain_tools = tools . to_langchain () # Get meta tools as well meta_tools = tools . meta_tools () langchain_meta_tools = meta_tools . to_langchain () # Combine all tools all_langchain_tools = list ( langchain_tools ) + list ( langchain_meta_tools ) print ( f \"Available tools for LangChain: { len ( all_langchain_tools ) } \" ) for tool in all_langchain_tools : print ( f \" - { tool . name } : { tool . description } \" ) # Create LangChain agent llm = ChatOpenAI ( model = \"gpt-4\" , temperature = 0 ) prompt = ChatPromptTemplate . from_messages ( [ ( \"system\" , \"You are an HR assistant. Use the meta tools to discover and execute relevant tools.\" , ), ( \"human\" , \" {input} \" ), ( \"placeholder\" , \" {agent_scratchpad} \" ), ] ) agent = create_tool_calling_agent ( llm , all_langchain_tools , prompt ) agent_executor = AgentExecutor ( agent = agent , tools = all_langchain_tools , verbose = True ) # Run the agent result = agent_executor . invoke ({ \"input\" : \"Find tools that can list employee data\" }) print ( f \" \\n Agent result: { result [ 'output' ] } \" ) except ImportError as e : print ( f \"LangChain dependencies not installed: { e } \" ) print ( \"Install with: pip install langchain-openai\" ) except Exception as e : print ( f \"LangChain example failed: { e } \" ) print () def main (): Run all examples print ( \"=\" * 60 ) print ( \"StackOne AI SDK - Meta Tools Examples\" ) print ( \"=\" * 60 ) print () # Basic examples that work without external APIs example_meta_tools_basic () example_meta_tools_with_execution () # Examples that require OpenAI API if os . getenv ( \"OPENAI_API_KEY\" ): example_with_openai () example_with_langchain () else : print ( \"Set OPENAI_API_KEY to run OpenAI and LangChain examples \\n \" ) print ( \"=\" * 60 ) print ( \"Examples completed!\" ) print ( \"=\" * 60 ) if __name__ == \"__main__\" : main ()","title":"Meta Tools Example"},{"location":"openai-integration/","text":"Openai Integration # This example demonstrates how to use StackOne tools with OpenAI's function calling. This example is runnable with the following command: uv run examples/openai_integration.py You can find out more about the OpenAI Function Calling API format here . from dotenv import load_dotenv from openai import OpenAI from stackone_ai import StackOneToolSet load_dotenv () account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" def handle_tool_calls ( tools , tool_calls ) -> list [ dict ]: results = [] for tool_call in tool_calls : tool = tools . get_tool ( tool_call . function . name ) if tool : results . append ( tool . execute ( tool_call . function . arguments )) return results def openai_integration () -> None : client = OpenAI () toolset = StackOneToolSet () # Filter tools to only the ones we need to avoid context window limits tools = toolset . fetch_tools ( actions = [ \"hris_get_employee\" , \"hris_list_employee_employments\" , \"hris_get_employee_employment\" , ], account_ids = [ account_id ], ) openai_tools = tools . to_openai () messages = [ { \"role\" : \"system\" , \"content\" : \"You are a helpful HR assistant.\" }, { \"role\" : \"user\" , \"content\" : f \"Can you get me information about employee with ID: { employee_id } ?\" , }, ] response = client . chat . completions . create ( model = \"gpt-4o-mini\" , messages = messages , tools = openai_tools , tool_choice = \"auto\" , ) # Verify we got a response with tool calls assert response . choices [ 0 ] . message . tool_calls is not None , \"Expected tool calls in response\" # Handle the tool calls and verify results results = handle_tool_calls ( tools , response . choices [ 0 ] . message . tool_calls ) assert results is not None and len ( results ) > 0 , \"Expected tool call results\" assert \"data\" in results [ 0 ], \"Expected data in tool call result\" # Verify we can continue the conversation with the results messages . extend ( [ { \"role\" : \"assistant\" , \"content\" : None , \"tool_calls\" : response . choices [ 0 ] . message . tool_calls }, { \"role\" : \"tool\" , \"tool_call_id\" : response . choices [ 0 ] . message . tool_calls [ 0 ] . id , \"content\" : str ( results [ 0 ]), }, ] ) # Verify the final response final_response = client . chat . completions . create ( model = \"gpt-4o-mini\" , messages = messages , tools = openai_tools , tool_choice = \"auto\" , ) assert final_response . choices [ 0 ] . message . content is not None , \"Expected final response content\" if __name__ == \"__main__\" : openai_integration ()","title":"OpenAI"},{"location":"openai-integration/#openai-integration","text":"This example demonstrates how to use StackOne tools with OpenAI's function calling. This example is runnable with the following command: uv run examples/openai_integration.py You can find out more about the OpenAI Function Calling API format here . from dotenv import load_dotenv from openai import OpenAI from stackone_ai import StackOneToolSet load_dotenv () account_id = \"45072196112816593343\" employee_id = \"c28xIQaWQ6MzM5MzczMDA2NzMzMzkwNzIwNA\" def handle_tool_calls ( tools , tool_calls ) -> list [ dict ]: results = [] for tool_call in tool_calls : tool = tools . get_tool ( tool_call . function . name ) if tool : results . append ( tool . execute ( tool_call . function . arguments )) return results def openai_integration () -> None : client = OpenAI () toolset = StackOneToolSet () # Filter tools to only the ones we need to avoid context window limits tools = toolset . fetch_tools ( actions = [ \"hris_get_employee\" , \"hris_list_employee_employments\" , \"hris_get_employee_employment\" , ], account_ids = [ account_id ], ) openai_tools = tools . to_openai () messages = [ { \"role\" : \"system\" , \"content\" : \"You are a helpful HR assistant.\" }, { \"role\" : \"user\" , \"content\" : f \"Can you get me information about employee with ID: { employee_id } ?\" , }, ] response = client . chat . completions . create ( model = \"gpt-4o-mini\" , messages = messages , tools = openai_tools , tool_choice = \"auto\" , ) # Verify we got a response with tool calls assert response . choices [ 0 ] . message . tool_calls is not None , \"Expected tool calls in response\" # Handle the tool calls and verify results results = handle_tool_calls ( tools , response . choices [ 0 ] . message . tool_calls ) assert results is not None and len ( results ) > 0 , \"Expected tool call results\" assert \"data\" in results [ 0 ], \"Expected data in tool call result\" # Verify we can continue the conversation with the results messages . extend ( [ { \"role\" : \"assistant\" , \"content\" : None , \"tool_calls\" : response . choices [ 0 ] . message . tool_calls }, { \"role\" : \"tool\" , \"tool_call_id\" : response . choices [ 0 ] . message . tool_calls [ 0 ] . id , \"content\" : str ( results [ 0 ]), }, ] ) # Verify the final response final_response = client . chat . completions . create ( model = \"gpt-4o-mini\" , messages = messages , tools = openai_tools , tool_choice = \"auto\" , ) assert final_response . choices [ 0 ] . message . content is not None , \"Expected final response content\" if __name__ == \"__main__\" : openai_integration ()","title":"Openai Integration"},{"location":"stackone-account-ids/","text":"Stackone Account Ids # Handling StackOne account IDs with the StackOne Tools. uv run examples/stackone_account_ids.py from dotenv import load_dotenv from stackone_ai import StackOneToolSet load_dotenv () def stackone_account_ids (): toolset = StackOneToolSet () Set the account ID whilst getting tools using fetch_tools(). tools = toolset . fetch_tools ( actions = [ \"hris_*\" ], account_ids = [ \"test_id\" ]) You can override the account ID on fetched tools. tools . set_account_id ( \"a_different_id\" ) employee_tool = tools . get_tool ( \"hris_get_employee\" ) assert employee_tool is not None You can even set the account ID on a per-tool basis. employee_tool . set_account_id ( \"again_another_id\" ) assert employee_tool . get_account_id () == \"again_another_id\" if __name__ == \"__main__\" : stackone_account_ids ()","title":"StackOne Account IDs"},{"location":"stackone-account-ids/#stackone-account-ids","text":"Handling StackOne account IDs with the StackOne Tools. uv run examples/stackone_account_ids.py from dotenv import load_dotenv from stackone_ai import StackOneToolSet load_dotenv () def stackone_account_ids (): toolset = StackOneToolSet () Set the account ID whilst getting tools using fetch_tools(). tools = toolset . fetch_tools ( actions = [ \"hris_*\" ], account_ids = [ \"test_id\" ]) You can override the account ID on fetched tools. tools . set_account_id ( \"a_different_id\" ) employee_tool = tools . get_tool ( \"hris_get_employee\" ) assert employee_tool is not None You can even set the account ID on a per-tool basis. employee_tool . set_account_id ( \"again_another_id\" ) assert employee_tool . get_account_id () == \"again_another_id\" if __name__ == \"__main__\" : stackone_account_ids ()","title":"Stackone Account Ids"}]}